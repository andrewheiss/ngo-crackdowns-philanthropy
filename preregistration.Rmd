---
title: "Preregistration, design, IRB"
date: "Last run: `r format(Sys.time(), '%F')`"
bibliography: manuscript/bibliography.bib
---

# Preregistration

We preregistered this study with the [Center for Open Science's](https://cos.io/) [Open Science Framework](https://osf.io/).

<p><a href="https://osf.io/dx973/register/565fb3678c5e4a66b5582f67" class="btn btn-primary btn-md btn-success" target="_blank">
<i class="fa fa-pencil-square" aria-hidden="true"></i>&nbsp;
OSF preregistration protocol &raquo;
</a></p>

We are participating in COS's [Preregistration Challenge](https://cos.io/our-services/prereg-more-information/), and will submit our final article to one of the following eligible journals:

- *Voluntas*
- *International Interactions*
- *Journal of Experimental Political Science*
- *Political Science Research Methods*
- *Research and Politics*

---

# Design

## Experimental conditions

| Condition            | 1 | 2 | 3 | 4 | 5 | 6 | 7 | 8 |
|----------------------|:-:|:-:|:-:|:-:|:-:|:-:|:-:|:-:|
| **Crackdown**        |   |   |   |   |   |   |   |   |
| Yes                  | • | • | • | • |   |   |   |   |
| No                   |   |   |   |   | • | • | • | • |
| *Expected donations* | + | + | + | + | ∅ | ∅ | ∅ | ∅ |
|                      |   |   |   |   |   |   |   |   |
| **Issue area**       |   |   |   |   |   |   |   |   |
| Humanitarian service | • | • |   |   | • | • |   |   |
| Human rights         |   |   | • | • |   |   | • | • |
| *Expected donations* | + | + | − | − | + | + | − | − |
|                      |   |   |   |   |   |   |   |   |
| **Type of funding**  |   |   |   |   |   |   |   |   |
| Government           | • |   | • |   | • |   | • |   |
| Private              |   | • |   | • |   | • |   | • |
| *Expected donations* | − | + | − | + | − | + | − | + |

## $f^2$ power analysis

The ultimate goal of our research project is to use Bayesian analysis is to test if the region of practical equivalence around the null value (i.e. the proposition that the average treatment effect of NGO crackdown is zero) excludes the posterior 95% HDI.

In this initial pilot study, we use standard frequentist methods to perform power analysis and estimate the desired sample size. We will use the effect size estimates from this study to inform the prior distribution of parameter values in future Bayesian-based experiments [@Kruschke:2015, 362]. 

```{r power-calculations}
library(pwr)
u_mine <- 1
# f2_mine <- cohen.ES(test = "f2", size = "small")$effect.size
f2_mine <- 0.02
sig_level_mine <- 0.05
power_mine = 0.90

survey_power <- pwr.f2.test(u = u_mine, v = NULL, f2 = f2_mine, 
                            sig.level = sig_level_mine, power = power_mine)

# n = u + v + 1
n_total <- survey_power$u + survey_power$v + 1
n_group <- n_total / (2 * 2 * 2)
```

Cohen's rules of thumb for $f^2$ power are 0.02, 0.15, and 0.35 for small, medium, and large effect sizes.

We are using a 2 × 2 × 2 design, manipulating the experimental condition, the issue area for the NGO, and the source of funding for the NGO. The formula for calculating the $f^2$-based sample size with [`pwr.f2.test`](https://www.rdocumentation.org/packages/pwr/versions/1.2-0/topics/pwr.f2.test) requires the following values:

- `u`: degrees of freedom for the numerator. This is a 2 × 2 × 2 design, so the degrees of freedom = $(2 - 1) \times (2 - 1) \times (2 - 1) = 1$
- `f2`: effect size. Here we use a small size, or `r f2_mine`.
- `sig.level`: significance level, or Type I error probability. Here we use `r sig_level_mine`.
- `power`: power of test, or 1 − Type II error probability. Here we use `r power_mine`.

Given these parameters, `pwr.f2.test` yields `v`, or the degrees of freedom for the denominator. The final sample size `n` is calculated as `u + v + 1`.

Thus, the total sample size is **`r round(n_total, 2)`**, with **`r round(n_group, 2)`** spread across 8 groups.

---

# Human subjects and IRB approval

This project has received IRB approval from the human subjects research committees at both BYU and Christopher Newport. We have included a generic version of our protocol below.

<p><a href="files/byu-irb-approval.pdf" class="btn btn-primary btn-md btn-success" target="_blank">
<i class="fa fa-check-circle" aria-hidden="true"></i>&nbsp;
BYU IRB approval
</a> 
&nbsp;
<a href="files/cnu-irb-approval.pdf" class="btn btn-primary btn-md btn-success" target="_blank">
<i class="fa fa-check-circle" aria-hidden="true"></i>&nbsp;
Christopher Newport IRB approval
</a></p>

\

## Project title

Charity During Crackdown: Analyzing the Impact of State Repression of NGOs on Philanthropy


## Purpose of the study

State repression of civil society organizations, in particular NGOs, has become ubiquitous over the last few decades. Besides undertaking violence towards costly organizations, states have also increasingly used legislation to crack down on NGOs. By creating barriers to their entry, funding, and operations, these laws restrict the space available for NGOs to engage in advocacy and provide services. How do such legal restrictions on NGOs impact private donors? With states increasingly providing funding for NGOs working in non-contentious issue areas, and a lack of philanthropic culture in many developing countries, numerous NGO rely on funds from private donors in Western countries. We use a survey experiment to examine the impact of state repression of NGOs on the preferences of private donors, as well as their actual behavior donating to besieged NGOs. In particular, we explore how state crackdown against NGOs changes private donors’ preferences and behavior based on the issue area of the organization, and the main source of its funds. Our results have important implications for understanding donor behavior, as well as for the sustainability of civil society organizations in developing countries. 


## Participant activities

Participants will fill out a survey experiment that (1) describes a prominent international NGO—the International Rescue Committee (IRC)—and (2) requests participants how much money they would hypothetically donate to the organization. We manipulate the vignette describing IRC’s work in three different ways to isolate the effect of civil society legal crackdowns on private philanthropy:

> The International Rescue Committee (IRC) focuses on {ISSUE AREA: humanitarian assistance for refugees | human rights for refugees} {MAIN MANIPULATION: and works in countries that have recently passed laws that harshly restrict nonprofit organizations}.
> 
> A substantial proportion of IRC’s funding comes from {FUNDING SOURCE: government | private donors}.

The survey also offers a vignette related to corporate philanthropy, describing Google’s partnership with IRC in late 2016. We manipulate the vignette using the same scenarios (presence or absence of a legal crackdown, issue area, and funding source) to isolate the effect of legal crackdowns on corporate social responsibility campaigns and perceptions of companies engaging in corporate philanthropy.

Finally, the survey asks participants a series of general questions related to their views of philanthropy, political knowledge, and general demographic features.


## Subject selection and recruitment

Participants of the survey experiment will be recruited via Amazon Mechanical Turk (MTurk), an online crowdsourcing platform that has been extensively used in social science research in recent years. MTurk allows researchers to recruit participants to perform tasks such as filling out surveys and opinion polls, participating in experiments, or coding the content of documents. Researchers advertise their studies as a human intelligence task (HIT) on MTurk, and participants choose only those HITs that interest them, given the promised price and estimated duration of the task. Participants are paid for completing HITs, and payment is transferred directly to participants’ credit cards immediately after the completion of a study.

Our study will be listed as “Survey on international nonprofit organizations” and will take approximately 5 minutes to complete. Participants will be paid \$0.75 for completing the experiment, commensurate with a \$9/hour wage. After selecting our HIT, participants will be taken directly to the survey experiment, which will be hosted on Qualtrics. MTurk rules state that participants can terminate the study by returning the HIT at any time, without penalty. 


## Data security and participant privacy

We will not collect personally identifiable data. MTurk workers are assigned a semi-random alphanumeric worker ID, which is the only information exposed to us as researchers. We collect MTurk worker IDs to distribute compensation after completion of the experiment and to exclude workers from future iterations of the study. Worker IDs will not be shared with anyone outside of the research team, will be removed from the data set, and will not be associated with any survey responses. Both Amazon and Qualtrics use SSL encryption (HTTPS) when collecting data from workers and transferring data to servers, so responses will remain confidential during the administration of the survey.

After collecting data and paying participants, we plan on creating a clean, anonymous, non-identifiable dataset to use for our analysis and for public distribution following the publication of the results of the study. This data will not contain any worker-identifiable information and will be safe to store and use without extra security measures.

Suparna Chaudhry and Andrew Heiss are co-investigators and will both have access to the clean, anonymized. Both have independently submitted IRB applications to their respective institutions. 


## Compensation

Participants will be paid \$0.75 for successfully completing the experiment, commensurate with a \$9/hour wage.

Previous studies have found that including simple questions to screen for attention can improve the results of MTurk experiments and filter out workers who try to get through the HIT as quickly as possible without reading the questions [@BerinskyMargolisSances:2014]. To ensure that participants only receive compensation for completing the full experiment, we include two attention check questions. The first (Q1.3) involves reading several sentences and following instructions to select specific responses. The second (Q4.8) is simpler and asks the respondent to select a single color from a list. 

Each attention check question serves a different purpose. The longer question (Q1.3) is designed to filter out respondents who are not paying attention at all and are trying to get a quick payout. Respondents who fail this question will exit the experiment and will not receive compensation. In an effort to not waste worker time, this is the first question after the consent form, so little participant time will have been wasted.

The shorter question (Q4.8) is designed to quickly check if the respondent is still paying attention near the end. Participants who fail this question will still be compensated, but we will account for their lack of attention in our statistical analysis and may omit their response.


## Risks and benefits

The study poses minimal risks to participants. The experiment does not include false information—the manipulations we make in the vignettes (shown between curly braces (`{}`)) only serve to make each fact about the International Rescue Committee (IRC) and Google more salient:

- “providing humanitarian assistance for refugees | advocating human rights for refugees”: IRC provides humanitarian assistance and engages in human rights advocacy for refugees
- “in countries where nonprofit organizations are harshly restricted”: IRC works in some countries that have passed anti-NGO laws, such as Egypt and Turkey, as well as countries with no such laws
- “A substantial proportion of IRC’s funding comes from government | private donors”: According to IRC’s most recent annual report, >25% of their income came from each of these sources
- Google has hosted several events to raise money for IRC, including initiatives in 2015 and 2016. We do not manipulate the amount of money raised.


# References
